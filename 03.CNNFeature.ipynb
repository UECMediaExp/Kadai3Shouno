{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験3-3 CNN の特徴抽出\n",
    "\n",
    "ここでは，CNN を用いて，中間層がどのような働きをしているかを考えてみます．\n",
    "道具としては演習 3-1, 3-2 で用いたクラスタリング手法と次元圧縮手法を用います．\n",
    "\n",
    "ここでは比較的単純な `ResNet18` モデルを題材に考えていきます．\n",
    "\n",
    "- 未学習の ResNet18 モデルの特徴表現\n",
    "- 学習済み ResNet18 モデルの特徴表現\n",
    "- ファインチューニングされた ResNet18 モデルの特徴表現\n",
    "\n",
    "これらのモデルの未知の画像に対する反応を取り出して，次元圧縮してCNNが画像をどのように見ているのかを可視化することを考えます．\n",
    "\n",
    "方法としては，対象としたモデルに対して，適切な特徴抽出層を定め，\n",
    "未知の画像を入力して，そこの出力を引っ張り出します．この出力は，画像を変換したものなので，\n",
    "CNN が見ている世界に他なりません．ただし高次元の特徴になっているために，次元圧縮とクラスタリングを使って可視化する，\n",
    "というのが今回の演習の趣旨になります．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18 をいじくる\n",
    "\n",
    "それでは `pytorch` で提供されている ResNet18 を弄くって，適切なモデルを再構築します．\n",
    "といっても，最後の識別層である `(fc)` 層を外すだけです．\n",
    "\n",
    "また，ファインチューニングする場合は，前回のファインチューニングの回と同じ要領で行うことになります．\n",
    "提供されている ResNet18 モデルは，`ImageNet1K` と呼ばれる1000クラスの画像データセットで学習されていますが，\n",
    "ここで対象としている画像セットは `CIFAR10` を対象とします．CIFAR10 は 10 クラス分のデータセットですので，\n",
    "1000 クラス分類するための `fc` 層を新たな 10クラス分の `fc` 層に取り替えて学習させ，その後，最後の層を外せばよいです．\n",
    "\n",
    "ここでは単純に取り払って，事前学習済みのモデルを調べていきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# ResNet18モデル（事前学習済み）\n",
    "model = resnet18(weights='DEFAULT') # ここで weights を指定しなければ，未学習のモデルとなる\n",
    "\n",
    "# fc 層の直前（avgpool層） までの部分モデルを作成（最後の1層をとっぱらったモデル）\n",
    "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの収集\n",
    "\n",
    "あとは，作成した `feature_extractor` モデルに，目的である `CIFAR10` を入力していきます．\n",
    "なお，画像の基本的な部分をあわせるため，平均と標準偏差を事前学習データである ImageNet1K に合わせるところは注意が必要です．\n",
    "\n",
    "ファインチューニングを施して学習させる場合は，CIFAR10 の平均と標準偏差に合わせたほうが良いので，`transform` を\n",
    "```python:\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet18 用にリサイズ\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "```\n",
    "あたりにしたほうが良いかもしれません．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# データ準備\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet18 用にリサイズ\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #事前学習した ImageNet1K の平均と標準偏差にあわせる\n",
    "])\n",
    "cifar10 = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "data_loader = torch.utils.data.DataLoader(cifar10, batch_size=100, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "# モデルを評価モードにして，データを喰わせる\n",
    "feature_extractor.eval()\n",
    "\n",
    "# 特徴抽出\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(data_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = feature_extractor(inputs)\n",
    "        features.append(outputs.cpu().numpy()) # GPU上のテンソルをCPU上に持ってくる\n",
    "        labels.extend(targets.numpy())\n",
    "\n",
    "features = np.concatenate(features)\n",
    "\n",
    "# ここで features は (10000, 512, 1, 1) の形状になっているはずなので，(10000, 512) に変形する\n",
    "features = features.squeeze(axis=(2, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可視化\n",
    "\n",
    "それでは，この特徴がクラスタリングできそうかどうか見ていきましょう．教師なし学習の場合は，ラベルを必要としないためにデータ表現の似た者同士を同じグループ（クラスタ）に入れていきます．\n",
    "まずは K-means 法でクラスタリングして，それを PCA で圧縮した次元で眺めてみます．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# K-meansクラスタリング\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "cluster_labels = kmeans.fit_predict(features)\n",
    "\n",
    "# プロット（次元削減後）\n",
    "pca = PCA(n_components=2)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].scatter(features_pca[:, 0], features_pca[:, 1], c=labels, cmap='tab10', s=5)\n",
    "ax[0].set_title('Distribution of CNN Features in PCA Space')\n",
    "ax[0].set_xlabel('PCA 1')\n",
    "ax[0].set_ylabel('PCA 2')\n",
    "ax[1].scatter(features_pca[:, 0], features_pca[:, 1], c=cluster_labels, cmap='tab10', s=5)\n",
    "ax[1].set_title('K-means on CNN Features')\n",
    "ax[1].set_xlabel('PCA 1')\n",
    "ax[1].set_ylabel('PCA 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "図の左側が，`CIFAR 10` についているラベルで，特徴を色分けしたもので，右側が K-means 法で色分けしたものです．\n",
    "なんとなくですが，色関係の対応が見えるような気がします．\n",
    "\n",
    "もう少しはっきりと可視化させたい場合は，`t-SNE` の出番です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE で次元圧縮\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=10)\n",
    "features_tsne = tsne.fit_transform(features)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].scatter(features_tsne[:, 0], features_tsne[:, 1], c=labels, cmap='tab10', s=5)\n",
    "ax[0].set_title('Distribution of CNN Features in TSNE Space')\n",
    "ax[0].set_xlabel('TSNE 1')\n",
    "ax[0].set_ylabel('TSNE 2')\n",
    "ax[1].scatter(features_tsne[:, 0], features_tsne[:, 1], c=cluster_labels, cmap='tab10', s=5)\n",
    "ax[1].set_title('K-means on CNN Features')\n",
    "ax[1].set_xlabel('TSNE 1')\n",
    "ax[1].set_ylabel('TSNE 2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今度は，かなり島状にデータが分布していて一部のデータはかなりきれいに分離できているのがわかります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験3-3\n",
    "\n",
    "1. 未学習の ResNet18 モデルに対して，上記と同様の特徴の分布の分析を行いなさい．\n",
    "2. 学習済みの ResNet18 にファインチューニングを施し，上記と同様の特徴の分布の分析を行いなさい．\n",
    "3. それぞれの特徴の表現が学習のなかでどの様に変化するかを考察しなさい．\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
