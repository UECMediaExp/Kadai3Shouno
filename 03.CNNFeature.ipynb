{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験3-3 CNN の特徴抽出\n",
    "\n",
    "ここでは，CNN を用いて，中間層がどのような働きをしているかを考えてみます．\n",
    "道具としては演習 3-1, 3-2 で用いたクラスタリング手法と次元圧縮手法を用います．\n",
    "\n",
    "ここでは比較的単純な `ResNet18` モデルを題材に考えていきます．\n",
    "\n",
    "- 未学習の ResNet18 モデルの特徴表現\n",
    "- 学習済み ResNet18 モデルの特徴表現\n",
    "- ファインチューニングされた ResNet18 モデルの特徴表現\n",
    "\n",
    "これらのモデルの未知の画像に対する反応を取り出して，次元圧縮してCNNが画像をどのように見ているのかを可視化することを考えます．\n",
    "\n",
    "方法としては，対象としたモデルに対して，適切な特徴抽出層を定め，\n",
    "未知の画像を入力して，そこの出力を引っ張り出します．この出力は，画像を変換したものなので，\n",
    "CNN が見ている世界に他なりません．ただし高次元の特徴になっているために，次元圧縮とクラスタリングを使って可視化する，\n",
    "というのが今回の演習の趣旨になります．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験準備\n",
    "\n",
    "この実験では\n",
    "\n",
    " - CIFAR10 データセット\n",
    " - ResNet18 の事前学習モデル\n",
    "\n",
    "を用います．これらは結構なディスク容量を消費するので，IED で実験を行う場合，少々小細工が必要となります．\n",
    "\n",
    "まず，実験2-4 と同様に，画像のデータセットをダウンロードする先を設定します．\n",
    "IED では `/usr/local/class/media/dataset` にありますので，\n",
    "```code:python\n",
    "datadir = `/usr/local/class/media/dataset/`\n",
    "```\n",
    "を指定してください．自分の家や gogle Colab で頑張る場合は，適宜設定してください．\n",
    "\n",
    "以下のコードではデータディレクトリを `./data` と指定していますが，IEDでこれをやっていくと使用制限を超えて，quota が溢れたというエラーが出てきて実験ができくなるので注意が必要です．\n",
    "\n",
    "また，学習済み係数も必要となります．これも実験2-4 と同様に\n",
    "```code:sh\n",
    "! mkdir -p ~/.cache/torch/hub/checkpoints\n",
    "! cd ~/.cache/torch/hub/checkpoints; find /usr/local/class/media/model/*.pth -exec ln -s {} \\;\n",
    "```\n",
    "のように，`pytorch` の実行用キャッシュディレクトリにダウンロードする学習係数ファイル (拡張子が `.pth` なもの)を持ってくることで，自分のフォルダの使用量を減らすことができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# GPU の指定\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # 使うGPUを指定\n",
    "\n",
    "# データディレクトリの指定 (IED の場合は，下のほうをコメントアウト)\n",
    "datadir = './data' # 自前のディレクトリに置く場合\n",
    "# datadir = '/usr/local/class/media/dataset' # IED で実験する場合\n",
    "\n",
    "# IED で実験する場合は， /usr/local/class/media/model/*.pth を ~/.cache/torch/hub/checkpoints にシンボリックリンクさせておく\n",
    "#\n",
    "# IED で実験する場合，下記のシェルコードを一度実行する．２度目以降はコメントにしておいて良い\n",
    "# ! mkdir -p ~/.cache/torch/hub/checkpoints\n",
    "# ! cd ~/.cache/torch/hub/checkpoints; find /usr/local/class/media/model/*.pth -exec ln -s {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18 をいじくる\n",
    "\n",
    "それでは `pytorch` で提供されている ResNet18 を弄くって，適切なモデルを再構築します．\n",
    "といっても，最後の識別層である `(fc)` 層を外すだけです．\n",
    "\n",
    "また，ファインチューニングする場合は，前回のファインチューニングの回と同じ要領で行うことになります．\n",
    "提供されている ResNet18 モデルは，`ImageNet1K` と呼ばれる1000クラスの画像データセットで学習されていますが，\n",
    "ここで対象としている画像セットは `CIFAR10` を対象とします．CIFAR10 は 10 クラス分のデータセットですので，\n",
    "1000 クラス分類するための `fc` 層を新たな 10クラス分の `fc` 層に取り替えて学習させ，その後，最後の層を外せばよいです．\n",
    "\n",
    "ここでは単純に取り払って，事前学習済みのモデルを調べていきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# ResNet18モデル（事前学習済み）\n",
    "model = resnet18(weights='DEFAULT') # ここで weights を指定しなければ，未学習のモデルとなる\n",
    "\n",
    "# fc 層の直前（avgpool層） までの部分モデルを作成（最後の1層をとっぱらったモデル）\n",
    "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの収集\n",
    "\n",
    "あとは，作成した `feature_extractor` モデルに，目的である `CIFAR10` を入力していきます．\n",
    "なお，画像の基本的な部分をあわせるため，平均と標準偏差を事前学習データである ImageNet1K に合わせるところは注意が必要です．\n",
    "\n",
    "ファインチューニングを施して学習させる場合は，CIFAR10 の平均と標準偏差に合わせたほうが良いので，`transform` を\n",
    "```python:\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet18 用にリサイズ\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "```\n",
    "あたりにしたほうが良いかもしれません．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# データ準備\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet18 用にリサイズ\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #事前学習した ImageNet1K の平均と標準偏差にあわせる\n",
    "])\n",
    "cifar10 = datasets.CIFAR10(root=datadir, train=False, transform=transform, download=True)\n",
    "data_loader = torch.utils.data.DataLoader(cifar10, batch_size=100, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "# モデルを評価モードにして，データを喰わせる\n",
    "feature_extractor.eval()\n",
    "\n",
    "# 特徴抽出\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(data_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = feature_extractor(inputs)\n",
    "        features.append(outputs.cpu().numpy()) # GPU上のテンソルをCPU上に持ってくる\n",
    "        labels.extend(targets.numpy())\n",
    "\n",
    "features = np.concatenate(features)\n",
    "\n",
    "# ここで features は (10000, 512, 1, 1) の形状になっているはずなので，(10000, 512) に変形する\n",
    "features = features.squeeze(axis=(2, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可視化\n",
    "\n",
    "それでは，この特徴がクラスタリングできそうかどうか見ていきましょう．教師なし学習の場合は，ラベルを必要としないためにデータ表現の似た者同士を同じグループ（クラスタ）に入れていきます．\n",
    "まずは K-means 法でクラスタリングして，それを PCA で圧縮した次元で眺めてみます．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# K-meansクラスタリング\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "cluster_labels = kmeans.fit_predict(features)\n",
    "\n",
    "# プロット（次元削減後）\n",
    "pca = PCA(n_components=10)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].scatter(features_pca[:, 0], features_pca[:, 1], c=labels, cmap='tab10', s=5)\n",
    "ax[0].set_title('Distribution of CNN Features in PCA Space')\n",
    "ax[0].set_xlabel('PC 1')\n",
    "ax[0].set_ylabel('PC 2')\n",
    "ax[1].scatter(features_pca[:, 0], features_pca[:, 1], c=cluster_labels, cmap='tab10', s=5)\n",
    "ax[1].set_title('K-means on CNN Features')\n",
    "ax[1].set_xlabel('PC 1')\n",
    "ax[1].set_ylabel('PC 2')\n",
    "\n",
    "\n",
    "# 3次元に拡張してプロットもしてみる\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax0 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax0.scatter(features_pca[:, 0], features_pca[:, 1], features_pca[:, 2], c=labels, cmap='tab10', s=5)\n",
    "ax0.set_xlabel('PC 1')\n",
    "ax0.set_ylabel('PC 2')\n",
    "ax0.set_zlabel('PC 3')\n",
    "ax0.set_title('Distribution of CNN Features in PCA Space')\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax1.scatter(features_pca[:, 0], features_pca[:, 1], features_pca[:, 2], c=cluster_labels, cmap='tab10', s=5)\n",
    "ax1.set_xlabel('PC 1')\n",
    "ax1.set_ylabel('PC 2')\n",
    "ax1.set_zlabel('PC 3')\n",
    "ax1.set_title('K-means on CNN Features')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "図の左側が，`CIFAR 10` についているラベルで，特徴を色分けしたもので，右側が K-means 法で色分けしたものです．\n",
    "なんとなくですが，色関係の対応が見えるような気がします．\n",
    "\n",
    "もう少しはっきりと可視化させたい場合は，`t-SNE` の出番です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE で次元圧縮\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=10)\n",
    "features_tsne = tsne.fit_transform(features)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].scatter(features_tsne[:, 0], features_tsne[:, 1], c=labels, cmap='tab10', s=5)\n",
    "ax[0].set_title('Distribution of CNN Features in TSNE Space')\n",
    "ax[0].set_xlabel('TSNE 1')\n",
    "ax[0].set_ylabel('TSNE 2')\n",
    "ax[1].scatter(features_tsne[:, 0], features_tsne[:, 1], c=cluster_labels, cmap='tab10', s=5)\n",
    "ax[1].set_title('K-means on CNN Features')\n",
    "ax[1].set_xlabel('TSNE 1')\n",
    "ax[1].set_ylabel('TSNE 2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今度は，かなり島状にデータが分布していて一部のデータはかなりきれいに分離できているのがわかります．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験3-3\n",
    "\n",
    "1. 未学習の ResNet18 モデルに対して，上記と同様の特徴の分布の分析を行いなさい．\n",
    "2. 学習済みの ResNet18 にファインチューニングを施し，上記と同様の特徴の分布の分析を行いなさい．\n",
    "3. それぞれの特徴の表現が学習のなかでどの様に変化するかを考察しなさい．\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
