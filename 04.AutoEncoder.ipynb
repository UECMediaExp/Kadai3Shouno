{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験3-4 自己符号化器による特徴表現の獲得\n",
    "\n",
    "ここでは自己符号化器（オートエンコーダ）に基づく教師なし学習を考えてみます．\n",
    "オートエンコーダは，入力と出力のペアを学習するモデルではありますが，入出力のペアには全く同じデータを与えるところに特徴があります．\n",
    "ある入力を与えたときに，入力と同じ出力を出すネットワークに意味があるのかという話になりますが，その中間表現には意味が出てきます．\n",
    "例えば中間層の次元を絞ったモデルでうまく学習できたときには，絞った次元でデータを表現し，その表現を使うともとのパターンを復元するだけの情報を持っているという\n",
    "ことになりますから，データに依存した次元圧縮が可能になっていると捉えることができます．\n",
    "\n",
    "ここでは，\n",
    "\n",
    "1. オートエンコーダによる MNIST の潜在表現の分析\n",
    "2. 変分オートエンコーダ(VAE) によるデータの生成と分析\n",
    "\n",
    "について考えたいと思います．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験準備\n",
    "\n",
    "この実験では\n",
    "\n",
    " - `MNIST`, `Fachin-MNIST`, `CIFAR10` データセット\n",
    " \n",
    "を用います．これらは結構なディスク容量を消費するので，IED で実験を行う場合，少々小細工が必要となります．\n",
    "\n",
    "実験2-4 と同様に，画像のデータセットをダウンロードする先を設定します．\n",
    "IED では `/usr/local/class/media/dataset` にありますので，\n",
    "```code:python\n",
    "datadir = `/usr/local/class/media/dataset/`\n",
    "```\n",
    "を指定してください．自分の家や google Colab で頑張る場合は，適宜設定してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# GPU の指定\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # 使うGPUを指定\n",
    "\n",
    "# データディレクトリの指定 (IED の場合は，下のほうをコメントアウト)\n",
    "datadir = './data' # 自前のディレクトリに置く場合\n",
    "# datadir = '/usr/local/class/media/dataset' # IED で実験する場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オートエンコーダの構成\n",
    "\n",
    "最初にオートエンコーダを考えたいと思います．このネットワークは符号化器(エンコーダ: encoder) と復号器(デコーダ: decoder) を組み合わせたモデルと考えることができます．\n",
    "このエンコーダとデコーダの接合部分が潜在表現となります．\n",
    "もでるとしてつくると下記のようなモデルとなります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルなオートエンコーダの構築\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# オートエンコーダモデル\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは MNIST を取り扱うために エンコーダとデコーダ，それぞれのネットワーク構成を\n",
    "\n",
    "- エンコーダ: 784-128-32-2\n",
    "- デコーダ: 2-32-128-784\n",
    "\n",
    "と対称になるようなモデル構成で考え，それぞれの層に非線形関数である `ReLU()` と `Sigmoid()` を設定しています．\n",
    "デコーダの最終層の非線形関数をシグモイド関数に設定しているのは，もとの MNIST のデータセットが [0, 1] の区間で定義されたデータであることに由来しています．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "\n",
    "このモデルに `MNIST` データセットを学習させることを考えます．\n",
    "まずはデータセットを準備します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット準備\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 1. データセットの前処理設定\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # 28x28 を 784次元に平坦化\n",
    "])\n",
    "\n",
    "# MNIST データセットの読み込み\n",
    "mnist_train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(mnist_train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オートエンコーダの学習\n",
    "\n",
    "次に学習させます．学習は，クラス判別とはことなり，エンコーダへ入力した信号と，デコーダの吐き出した出力信号との比較になります．\n",
    "このとき，これらが同じになるようにするのがオートエンコーダのキモの部分なので，自分との違いを損失関数に設定する必要があります．\n",
    "この場合は `nn.MSELoss()` 関数を使います．\n",
    "\n",
    "また，学習に用いる最適化手法は `SGD` を使っても良いのですが，ここでは時間短縮のため `Adam` と呼ばれる方法を取ります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# モデル定義\n",
    "model = AutoEncoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 20\n",
    "history = []\n",
    "# モデル学習\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for x, _ in dataloader:\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        _, decoded = model(x)\n",
    "        loss = criterion(decoded, x)\n",
    "        history.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader.dataset):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(history, label=\"loss\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "無事に学習できているようなので中間層の表現を眺めていきます．\n",
    "中間層の表現を得るには，モデルのエンコーダ部分を収集します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, targets in dataloader:\n",
    "        x = x.to(device)\n",
    "        encoded, _ = model(x)  # エンコードされた値を取得\n",
    "        encoded_data.append(encoded.cpu())\n",
    "        labels.append(targets)\n",
    "\n",
    "encoded_data = torch.cat(encoded_data)  # 全データを結合\n",
    "labels = torch.cat(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に集めたデータは，２次元のデータなので，これをラベルとともに散布図とします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(encoded_data[:, 0], encoded_data[:, 1], c=labels, cmap='tab10', alpha=0.7)\n",
    "plt.colorbar(scatter, ticks=range(10), label='Digit Label')\n",
    "plt.xlabel('Encoded Dimension 1')\n",
    "plt.ylabel('Encoded Dimension 2')\n",
    "plt.title('2D Encoded Representation of MNIST')\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは，上記(0, 0)の付近であればなんかパターンがいくつか混ざって混沌とした状況なので，サンプルしてパターンを生成してみます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成したいデータの数\n",
    "num_generation = 10\n",
    "\n",
    "# サンプルデータを生成 mu を中心に sigma の標準偏差な乱数生成\n",
    "mu = torch.tensor([0, 0])\n",
    "sigma = torch.tensor([1, 1])\n",
    "std_rand = torch.randn(num_generation, 2)\n",
    "sample_embeddeing = (sigma * std_rand + mu).to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated = model.decoder(sample_embeddeing).view(-1, 28, 28).cpu()\n",
    "    \n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(num_generation):\n",
    "    ax = plt.subplot(2, num_generation, i+1)\n",
    "    plt.imshow(generated[i], cmap='gray')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 変分自己符号化器(VAE)\n",
    "\n",
    "変分自己符号化器（Variational Auto Encoder: VAE）は，AEの亜種で，潜在表現を既知の確率分布で表すことができるようにしたモデルです．\n",
    "潜在表現を既知の確率分布（通常は多次元正規分布）に表現させようとすることにしているため，逆に潜在空間の上で，その分布に基づいた乱数をふることで\n",
    "乱数からデータを生成させることができるようになります．\n",
    "これに基づいて画像などのデータ生成をさせるというのがVAEの主たる使い方になります．（Diffusion モデルのご先祖だと思ってもらっても良いです）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル構成は下記の通りになります．\n",
    "ここでは潜在空間は２次元の空間となるので２次元の正規分布が間にはさまるような形になっていると思ってもらって大丈夫です．\n",
    "符号化器を正規分布化するために，中心パラメータを制御する `fc_mu` と分散を制御する `fc_logvar` が付け加えられています．\n",
    "\n",
    "`reparameterize()` 関数は，ネットワークの中心で正規分布化するための関数で，ここのなかで乱数を生成させ，デコードさせることで新奇なパターンをどんどん生成させることができるようにします．\n",
    "（この生成方法はリパラメトリゼーショントリックと呼ばれます）\n",
    "したがって，学習時にはこの正規分布がどこにあるのかを獲得する必要が出てきます．\n",
    "このため `forward()` 関数では，復号化したデータ以外にも，分布の中心 `mu` と `logvar` を返すような形になります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder: 潜在空間の平均と標準偏差を出力\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(32, 2)      # 2次元分の平均 μ\n",
    "        self.fc_logvar = nn.Linear(32, 2)  # 2次元分の対数分散 log(σ^2)\n",
    "\n",
    "        # Decoder: 潜在空間からデータを再構成\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # 再パラメータ化トリック\n",
    "        std = torch.exp(0.5 * logvar)  # 標準偏差\n",
    "        epsilon = torch.randn_like(std)  # 標準正規分布からサンプリング\n",
    "        return mu + std * epsilon # 学習された正規分布へマッピング\n",
    "\n",
    "    def forward(self, x):\n",
    "        # エンコーダ\n",
    "        encoded = self.encoder(x)\n",
    "        mu = self.fc_mu(encoded)\n",
    "        logvar = self.fc_logvar(encoded)\n",
    "        \n",
    "        # 再パラメータ化\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        # デコーダ\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習では，復号データと入力データの差分だけではなく，符号化データが与えた確率分布に従っているように細工が必要となります．このため，単純な再構成誤差だけでなく，KLダイバージェンスと呼ばれる項を損失関数に追加します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def vae_loss(reconstructed, x, mu, logvar):\n",
    "    # 再構成損失 (MSE または BCE)\n",
    "    reconstruction_loss = nn.functional.binary_cross_entropy(reconstructed, x, reduction='sum')\n",
    "    \n",
    "    # KLダイバージェンス\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return reconstruction_loss + kl_divergence\n",
    "\n",
    "\n",
    "# デバイス設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# モデルと最適化器の準備\n",
    "vae = VAE().to(device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# 学習ループ\n",
    "num_epochs = 20\n",
    "vae.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch, (x, _) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # 順伝播\n",
    "        reconstructed, mu, logvar = vae(x)\n",
    "        \n",
    "        # 損失計算\n",
    "        loss = vae_loss(reconstructed, x, mu, logvar)\n",
    "        \n",
    "        # 逆伝播とパラメータ更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(dataloader.dataset):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "encoded_data = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        _, mu, _ = vae(x)  # 平均値を潜在変数として使用\n",
    "        encoded_data.append(mu.cpu())\n",
    "        labels.append(y)\n",
    "\n",
    "encoded_data = torch.cat(encoded_data)\n",
    "labels = torch.cat(labels)\n",
    "\n",
    "# 散布図のプロット\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(encoded_data[:, 0], encoded_data[:, 1], c=labels, cmap='tab10', alpha=0.7)\n",
    "plt.colorbar(scatter, ticks=range(10), label='Digit Label')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.title('Latent Space Representation (VAE)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは，２次元の潜在空間上で適当な２点を選んで線分を構成し，その線上のデータがどのようなデータに再構成されるかを眺めてみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2つの潜在ベクトル間を補間\n",
    "z1 = (1.5 * torch.randn(1, 2)).to(device)  # 潜在ベクトル1\n",
    "z2 = (1.5 * torch.randn(1, 2)).to(device)  # 潜在ベクトル2\n",
    "t = torch.linspace(0, 1, steps=10).unsqueeze(1).to(device)\n",
    "interpolated_z = t * z1 + (1 - t) * z2\n",
    "\n",
    "# データ生成\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    interpolated_images = vae.decoder(interpolated_z)\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(interpolated_images[i].view(28, 28).cpu().numpy(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Latent Space Interpolation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験 3-4\n",
    "\n",
    "1. AE, VAE から得られた潜在空間表現に k-meas 法を施し，どのようなクラスタが得られるかを図示しなさい．\n",
    "2. AE, VAE の構成に畳み込み演算を入れた場合，潜在空間がどのようになるかを図示しなさい．\n",
    "3. `Fashion-MNIST` と `CIFAR10` の潜在空間表現がどのようになるかを図示しなさい．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
