{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### この実験は選択実験とします．難しい場合はパスしても構いません．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験3-5 自己教師あり学習\n",
    "\n",
    "自己教師あり学習は，比較的最近に提案された学習手法で，ラベルを必要としない教師なし学習の手法として着目されています．\n",
    "その基本的な考え方は，\n",
    "\n",
    "- 同じデータから派生されるデータ拡張は同じ（似たような）表現にマップされるべき\n",
    "- 異なるデータ（のデータ拡張）は，異なる表現になるべき\n",
    "\n",
    "というアイディアに基づいた学習手法です．\n",
    "教師あり学習では，ラベルとよばれる絶対的な指標がありますが，ここでは，表現が似るべきというわりと曖昧なコンセプトに基づいて学習を考えていきます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実験準備\n",
    "\n",
    "この実験では\n",
    "\n",
    " - `STL10`, `CIFAR10`, `Fashin-MNIST` データセット\n",
    " \n",
    "を用います．これらは結構なディスク容量を消費するので，IED で実験を行う場合，少々小細工が必要となります．\n",
    "\n",
    "まず，実験2-4 と同様に，画像のデータセットをダウンロードする先を設定します．\n",
    "IED では `/usr/local/class/media/dataset` にありますので，\n",
    "```code:python\n",
    "datadir = '/usr/local/class/media/dataset/'\n",
    "```\n",
    "を指定してください．自分の家や google Colab で頑張る場合は，適宜設定してください．\n",
    "\n",
    "以下のコードではデータディレクトリを `./data` と指定していますが，IEDでこれをやっていくと使用制限を超えて，quota が溢れたというエラーが出てきて実験ができくなるので注意が必要です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# GPU の指定\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # 使うGPUを指定\n",
    "\n",
    "# データディレクトリの指定 (IED の場合は，下のほうをコメントアウト)\n",
    "datadir = './data' # 自前のディレクトリに置く場合\n",
    "# datadir = '/usr/local/class/media/dataset' # IED で実験する場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自己教師付き学習のためのデータローダー\n",
    "\n",
    "ここでは SimCLR （の簡易版）を考えてみます．\n",
    "自己教師あり学習のキーポイントの一つはデータ拡張の部分にあります．\n",
    "すなわち，一つの画像から，異なるデータ拡張を施した画像のペアを生成させます．\n",
    "\n",
    "ここではランダムな，画像切り抜き，フリップを考えています．\n",
    "データセットとしては `CIFAR10` や `STL10` を考えればよいです．ここでは視認性をとって `STL10` で実験を行います．\n",
    "なお，`STL10` データセットはかなり大きいデータセットなので，ディスク容量には気をつけてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "# 基本となるデータセットの設定\n",
    "#base_dataset = datasets.CIFAR10(root=datadir, train=True, download=True, transform=None)\n",
    "base_dataset = datasets.STL10(root=datadir, split='train', download=True, transform=None)\n",
    "\n",
    "#cifar10_labels_map = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "stl10_labels_map = ['airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck']\n",
    "labels_map = stl10_labels_map\n",
    "\n",
    "# CIFAR-10 は 32x32 の画像サイズ, STL-10 は 96x96 の画像サイズ\n",
    "# CIFAR-10 でやる場合は，RandomResizedCrop の size を 32 にする必要がある\n",
    "# データセットの画像サイズ\n",
    "SIZE = 96\n",
    "W, H = SIZE, SIZE\n",
    "\n",
    "transform_original = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_1 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_2 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=SIZE),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# データ拡張を適用したデータセットを作成するクラス\n",
    "class SelfSupervisedDataset(Dataset):\n",
    "    def __init__(self, base_dataset, transform_1, transform_2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            base_dataset (Dataset): 元となるデータセット（例: STL-10）。\n",
    "            transform_1 (callable): 1つ目のデータ拡張。\n",
    "            transform_2 (callable): 2つ目のデータ拡張。\n",
    "        \"\"\"\n",
    "        self.base_dataset = base_dataset\n",
    "        self.transform_1 = transform_1\n",
    "        self.transform_2 = transform_2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.base_dataset[idx]  # 元画像とラベルを取得\n",
    "\n",
    "        # base が PIL 形式であることを仮定\n",
    "        # なので，ToTensor を base_dataset の段階でとるとしくじる\n",
    "        # img = transforms.ToPILImage()(img) # tensor -> PILImage\n",
    "\n",
    "        augmented_1 = self.transform_1(img)  # データ拡張1を適用\n",
    "        augmented_2 = self.transform_2(img)  # データ拡張2を適用\n",
    "        return augmented_1, augmented_2, label\n",
    "\n",
    "\n",
    "#self_supervised_dataset = SelfSupervisedDataset(base_dataset, transform_1, transform_2)\n",
    "self_supervised_dataset = SelfSupervisedDataset(base_dataset, transform_original, transform_1)\n",
    "\n",
    "# DataLoaderを作成\n",
    "dataloader = DataLoader(self_supervised_dataset, batch_size=256, shuffle=True, num_workers=4) # num_workers は適宜変更する．デッドロックの可能性あり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得データの確認\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# サンプルループ（1バッチ分のデータを取得）\n",
    "for batch in dataloader:\n",
    "    augmented_1, augmented_2, labels = batch\n",
    "    print(f\"Augmented 1 shape: {augmented_1.shape}, Augmented 2 shape: {augmented_2.shape}\")\n",
    "    break\n",
    "\n",
    "#next(iter(dataloader)) # num_workers と，next(iter(dataloader)) の組み合わせはデッドロックを生じさせる可能性あり\n",
    "fig, ax = plt.subplots(3, 2, figsize=(8, 12))\n",
    "for i in range(3):\n",
    "    ax[i, 0].imshow(augmented_1[i].permute(1, 2, 0))\n",
    "    ax[i, 1].imshow(augmented_2[i].permute(1, 2, 0))\n",
    "    ax[i, 0].set_title(f\"Augmented 1: {labels_map[labels[i].item()]}\")\n",
    "    ax[i, 1].set_title(f\"Augmented 2: {labels_map[labels[i].item()]}\")\n",
    "    ax[i, 0].axis(\"off\")\n",
    "    ax[i, 1].axis(\"off\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimCLR の構成\n",
    "\n",
    "### ネットワークモデルの構成\n",
    "\n",
    "ここまで来たら，あとは好きなようにモデルを組み立てれば良いのですが，ここでは SimCLR を利用するため，\n",
    "ネットワークの構成としては，表現を得るためのモデル(`encoder`)と，その表現を投影し似ているかどうかを判定するためのモデル(`projector`)を規定します．\n",
    "\n",
    "- `encoder`: 単純な CNN で，３回 畳み込み+プーリング操作 を行い，特徴層を作ります．\n",
    "- `projector`: 特徴を MLP で射影し，64次元のベクトルとして取り出します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, W, H):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1), # 3xWxH -> 64xWxH\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 64xWxH -> 64x(W/2)x(H/2)\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 64x(W/4)x(H/4)\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 64x(W/8)x(H/8)\n",
    "            nn.Flatten() # 64x(W/8)x(H/8) -> 64*(W/8)*(H/8)\n",
    "        )\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(64*(W//8)*(H//8), 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.projector(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 損失関数の設計\n",
    "\n",
    "損失関数は，投影された先の特徴量間の類似度を,正例の場合は大きく，負例の場合は小さくなるように設計します．\n",
    "これは NT-Xent 関数と呼ばれ，下記のように定義されます．\n",
    "\n",
    "ドラフト版では 余弦関数を用いたもので規定していましたが，いわゆるモード崩壊が起きてしまうので，`NT-Xent loss` 関数と呼ばれる損失を頑張って書いておきました．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NT-Xent Loss の実装例\n",
    "# 同じ画像から作られたペア→正例\n",
    "# 異なる画像から作られたペア→負例\n",
    "# 正例同士は似て，負例同士は異なるようにロスを設計する\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature):\n",
    "    z = torch.cat([z1, z2], dim=0)\n",
    "    n = z.size(0)\n",
    "    sim_matrix = torch.matmul(z, z.T) / temperature\n",
    "    # 数値安定性を考慮して，行の最大値を基準に差っ引いとく\n",
    "    sim_matrix = sim_matrix - torch.max(sim_matrix, dim=1, keepdim=True)[0]\n",
    "    sim_matrix = torch.exp(sim_matrix)\n",
    "\n",
    "    # 対角成分は同じ画像同士の類似度なので正例，それ以外が負例\n",
    "    mask = (torch.ones_like(sim_matrix) - torch.eye(n, device=sim_matrix.device)).bool()\n",
    "    pos_sim = sim_matrix[range(n), range(n)]\n",
    "    neg_sim = sim_matrix[mask].reshape(n, -1)\n",
    "\n",
    "    loss = -torch.log(pos_sim / (pos_sim + neg_sim.sum(dim=-1)))\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimCLR での学習\n",
    "\n",
    "データとモデルと損失関数の準備が終わったので，学習させます．\n",
    "学習ループは，下記のようにかけます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SimpleCNN(W, H).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "history = [] # 学習履歴\n",
    "num_epochs = 15 # エポック数，性能に合わせて調整\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for (images1, images2, _) in dataloader:\n",
    "        images1, images2 = images1.to(device), images2.to(device)\n",
    "\n",
    "        # 特徴抽出→projector\n",
    "        z1 = model(images1)\n",
    "        z2 = model(images2)\n",
    "\n",
    "        # 類似性損失: NT-Xent 損失を計算\n",
    "        loss = nt_xent_loss(z1, z2, temperature=0.4)  # temperature はハイパーパラメータ\n",
    "\n",
    "        history.append(loss.item())\n",
    "\n",
    "        # 学習\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多分，これでなんとか回って，ロスが下がるはずです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history のプロット\n",
    "plt.semilogy(history)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能評価\n",
    "\n",
    "`SimpleCNN.encoder` がうまく学習できていればよいな，と思って性能を測ってみます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = datasets.CIFAR10(root=datadir, train=True, download=True, transform=transform_original)\n",
    "#test_dataset = datasets.CIFAR10(root=datadir, train=False, download=True, transform=transform_original)\n",
    "train_dataset = datasets.STL10(root=datadir, split='train', download=True, transform=transform_original)\n",
    "test_dataset = datasets.STL10(root=datadir, split='test', download=True, transform=transform_original)\n",
    "\n",
    "train_ratio = 1.0 # 学習パターンを使う割合\n",
    "num_train_samples = int(len(train_dataset) * train_ratio)\n",
    "subset_train_dataset, _ = torch.utils.data.random_split(train_dataset, [num_train_samples, len(train_dataset) - num_train_samples])\n",
    "\n",
    "train_dataloader = DataLoader(subset_train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴抽出層は上で学習したものを固定して使う\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 簡単な分類器を訓練 3層のMLP\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(64*(W//8)*(H//8), 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10).to(device)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history = []\n",
    "\n",
    "# ラベルを使って学習\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    average_loss = 0.0\n",
    "    for (images, labels) in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        features = model.encoder(images)\n",
    "        outputs = classifier(features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        history.append(loss.item())\n",
    "        average_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss /= len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {average_loss}\")\n",
    "    \n",
    "plt.semilogy(history)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あとは，識別性能をテストでーたで測っておきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 識別性能をテストデータ測る\n",
    "# ついでに混同行列も作成\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "conf_matrix = np.zeros((10, 10))\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in test_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        features = model.encoder(images)\n",
    "        outputs = classifier(features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        conf_matrix += confusion_matrix(labels.cpu().numpy(), predicted.cpu().numpy(), labels=np.arange(10))\n",
    "\n",
    "conf_matrix = np.array(conf_matrix, dtype=int)\n",
    "correct = np.sum(np.diag(conf_matrix))\n",
    "total = np.sum(conf_matrix)\n",
    "print(f\"Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels_map, yticklabels=labels_map)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix{:.4f}\".format(correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まぁ，それなりに．\n",
    "なお，`STL-10` の 識別性能は下記で確認できます．\n",
    "\n",
    "https://paperswithcode.com/sota/image-classification-on-stl-10?tag_filter=231%2C0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験3-5\n",
    "\n",
    "1. 自己教師あり学習による識別器を構成し，`CIFAR10` を用いた場合の識別性能を評価しなさい．（識別器はロジスティック回帰やSVM を用いて構わない）\n",
    "2. 自己教師あり学習によって得られた `CIFAR10` の特徴表現を，PCA や t-SNE を用いて図示し，各クラスのデータが構造を持つかどうかを考察しなさい．\n",
    "3. 自己教師あり学習によって得られた `CIFAR10` の特徴表現を k-means 法によりクラスタリングを行い，自己教師あり学習の特徴がクラスタリングに有効かどうかを評価しなさい．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
