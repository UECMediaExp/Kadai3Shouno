{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験3-5 自己教師あり学習\n",
    "\n",
    "自己教師あり学習は，比較的最近に提案された学習手法で，ラベルを必要としない教師なし学習の手法として着目されています．\n",
    "その基本的な考え方は，\n",
    "\n",
    "- 同じデータから派生されるデータ拡張は同じ（似たような）表現にマップされるべき\n",
    "- 異なるデータ（のデータ拡張）は，異なる表現になるべき\n",
    "\n",
    "というアイディアに基づいた学習手法です．\n",
    "教師あり学習では，ラベルとよばれる絶対的な指標がありますが，ここでは，表現が似るべきというわりと曖昧なコンセプトに基づいて学習を考えていきます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは SimCLR （の簡易版）を考えてみます．\n",
    "キーポイントはデータ拡張の部分にあります．\n",
    "\n",
    "ここではランダムな，画像切り抜き，フリップ，色補正などを考えています．\n",
    "データセットとしては `CIFAR10` を考えます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', download=True, transform=transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークの構成としては，表現を得るためのモデル(`encoder`)と，その表現を投影し似ているかどうかを判定するためのモデル(`projector`)を規定します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(8*8*128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.projector(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数は，投影された先の特徴量間の類似度を最大化するようにコサイン類似度で設計します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに学習ループは，下記のようにかきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "# ToPILImageインスタンスを作成\n",
    "to_pil = ToPILImage()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for (images, _) in dataloader:\n",
    "        # 画像ペア生成\n",
    "        \n",
    "        # 画像を PIL に変換してデータ拡張を2回適用\n",
    "        images1 = torch.stack([transform(to_pil(img)) for img in images])\n",
    "        images2 = torch.stack([transform(to_pil(img)) for img in images])\n",
    "\n",
    "        images1, images2 = images1.to(device), images2.to(device)\n",
    "\n",
    "        # 特徴抽出\n",
    "        z1 = model(images1)\n",
    "        z2 = model(images2)\n",
    "\n",
    "        # 類似性損失の計算\n",
    "        targets = torch.ones(z1.size(0)).to(z1.device)  # 正例ペア\n",
    "        loss = criterion(z1, z2, targets)\n",
    "\n",
    "        # 学習\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴を抽出して固定\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 簡単な分類器を訓練\n",
    "classifier = nn.Linear(128, 10)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# CIFAR-10のラベルを使って学習\n",
    "for epoch in range(5):\n",
    "    for (images, labels) in dataloader:\n",
    "        features = model(images)\n",
    "        outputs = classifier(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験3-5\n",
    "\n",
    "1. 自己教師あり学習による識別器を構成し，`CIFAR10` を用いた場合の識別性能を評価しなさい．（識別器はロジスティック回帰やSVM を用いて構わない）\n",
    "2. 自己教師あり学習によって得られた `CIFAR10` の特徴表現を，PCA や t-SNE を用いて図示し，各クラスのデータが構造を持つかどうかを考察しなさい．\n",
    "3. 自己教師あり学習によって得られた `CIFAR10` の特徴表現を k-means 法によりクラスタリングを行い，自己教師あり学習の特徴がクラスタリングに有効かどうかを評価しなさい．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
